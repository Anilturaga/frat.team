<!doctype html>

<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>WebcamJS Test Page</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
</head>

<body>
    <video id="player" controls autoplay style="display: none;"></video>
    <canvas id="canvas" width=320 height=240 style="display: none;"></canvas>
    <button id="capture" style="display: none;">Capture</button>
    <script>
        const player = document.getElementById('player');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        const captureButton = document.getElementById('capture');
        ctx = canvas.getContext('2d');
        ctx.fillStyle = "rgba(255, 0, 0, 0.5)";
        const constraints = {
            video: true,
        };
        setInterval(smartAttendance, 3000);
        /*captureButton.addEventListener('click', () => {
        });*/
        function smartAttendance() {
            // Draw the video frame to the canvas.
            context.drawImage(player, 0, 0, canvas.width, canvas.height);
            main();
        }
        // Attach the video stream to the video element and autoplay.
        navigator.mediaDevices.getUserMedia(constraints)
            .then((stream) => {
                player.srcObject = stream;
            });
        async function main() {
            // Load the model.
            const model = await blazeface.load();

            // Pass in an image or video to the model. The model returns an array of
            // bounding boxes, probabilities, and landmarks, one for each detected face.

            const returnTensors = false; // Pass in `true` to get tensors back, rather than values.
            const predictions = await model.estimateFaces(document.getElementById('canvas'), returnTensors);

            if (predictions.length > 0) {
                /*
                `predictions` is an array of objects describing each detected face, for example:
            
                [
                  {
                    topLeft: [232.28, 145.26],
                    bottomRight: [449.75, 308.36],
                    probability: [0.998],
                    landmarks: [
                      [295.13, 177.64], // right eye
                      [382.32, 175.56], // left eye
                      [341.18, 205.03], // nose
                      [345.12, 250.61], // mouth
                      [252.76, 211.37], // right ear
                      [431.20, 204.93] // left ear
                    ]
                  }
                ]
                */

                for (let i = 0; i < predictions.length; i++) {
                    const start = predictions[i].topLeft;
                    const end = predictions[i].bottomRight;
                    const size = [end[0] - start[0], end[1] - start[1]];
                    console.log("pred", start, end, size)
                    // Render a rectangle over each detected face.
                    //ctx.fillRect(start[0], start[1], size[0], size[1]);
                }
            }
        }

    </script>

</body>

</html>